{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tIhKb0gG1MP0i1rm7_qZEhGM5IWGHTyZ",
      "authorship_tag": "ABX9TyPU+VZC1+B4h2GgydqjJgrd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 5주차: 자신의 데이터를 활용한 지도학습 및 비지도학습 모델 구현\n",
        "---\n",
        "## 보고서: 한문고전번역 모델 구현\n",
        "\n",
        "### 1. **소개**\n",
        "\n",
        "이 보고서는 한문 고전 문서를 번역하기 위한 모델 구현 과정을 설명합니다. 본 과제에서는 문서 전처리와 `seq2seq` 모델을 사용한 지도학습 기반 번역 모델을 개발하였으며, 이후 비지도 학습 기법을 활용하여 모델 개선을 시도했습니다. 비지도 학습의 주요 내용으로는 TF-IDF 벡터화와 클러스터링을 포함하고 있습니다.\n",
        "\n",
        "### 2. **데이터 전처리**\n",
        "\n",
        "#### 2.1 데이터 로딩 및 전처리\n",
        "\n",
        "- **데이터 로딩**: 데이터셋을 로드한 후, 한문 고전 문서들의 텍스트 데이터를 학습에 사용할 수 있게 변환하였습니다.\n",
        "- **변환 과정**:\n",
        "  - 이미 이전 차시에서 결측치 처리와 토큰화를 진행한 후, 저장한 데이터를 로드하였기에 별도의 전처리 과정은 거치지 않고, 토큰화된 단어 리스트를 하나의 문장으로 변환해주었습니다.\n",
        "\n",
        "#### 2.2 `seq2seq` 모델 개발\n",
        "\n",
        "- **모델 설계**: 입력 시퀀스를 받아 출력 시퀀스를 생성하는 `seq2seq` 모델을 설계하였습니다. 이 모델은 인코더와 디코더로 구성되며, 문장 단위의 번역을 목표로 하였습니다.\n",
        "우선, 데이터를 학습 데이터와 테스트 데이터로 분리하였습니다(9:1). 학습 시간의 문제와 문법적 난이도를 고려하여 길이가 5이하인 짧은 문장들만 추려 학습을 진행하였습니다.\n",
        "- **모델 학습**: 준비된 데이터로 모델을 학습시켰습니다. 학습 과정에서 하이퍼파라미터 조정과 모델 튜닝을 수행하였으나, 결과적으로 모델의 번역 정확도가 기대에 미치지 못하였습니다. 아래는 모델이 번역해준 한 문장 예시입니다.\n",
        "```\n",
        "> 庚 寅 氷\n",
        "= 얼음 이 얼었다\n",
        "< 가 큰 청나라 <EOS>\n",
        "```\n",
        "\n",
        "### 3. **모델 평가**\n",
        "\n",
        "모델의 성능을 평가하기 위해, 어텐션 메커니즘을 사용한 시각화를 통해 입력 문장의 각 단어에 대한 모델의 주의 집중도를 측정하였습니다. 어텐션 시각화 결과 대부분의 값이 0.2 이하로 나타나, 모델이 입력 문장의 특정 단어에 충분한 주의를 기울이지 못했음을 확인할 수 있었습니다.\n",
        "\n",
        "해당 부분에 대해서는 학습 과정의 문제보다는 한문이라는 언어의 특성 때문이라고 생각되어, 최종논문의 실패 요인 분석으로 자세하게 다룰 예정입니다.\n",
        "\n",
        "### 4. **비지도 학습 적용**\n",
        "\n",
        "#### 4.1 TF-IDF 벡터화\n",
        "\n",
        "- **TF-IDF 변환**: 전처리된 문서들을 TF-IDF 벡터로 변환하였습니다. TF-IDF 벡터화는 각 문서의 중요 단어를 수치적으로 표현하여, 문서 간의 유사성을 분석할 수 있게 합니다.\n",
        "- **행렬 생성**: TF-IDF 행렬의 크기는 (1022162, 346378)으로, 매우 희소한 행렬이 생성되었습니다.\n",
        "\n",
        "#### 4.2 클러스터링\n",
        "\n",
        "- **클러스터링 기법**: TF-IDF 벡터를 기반으로 K-means 클러스터링을 수행하여 문서들을 여러 개의 클러스터로 그룹화하였습니다.\n",
        "- **클러스터 분석**: 클러스터별로 상위 단어를 추출하여 각 클러스터의 주요 주제를 파악하였습니다. 예를 들어, 클러스터 1은 '전망', '단자', '차하' 등의 단어가 포함된 문서들로 구성되었으며, 이는 특정 주제나 문서 유형을 반영할 수 있습니다.\n",
        "\n",
        "#### 4.3 비지도 학습과 번역 모델 개선의 연관성\n",
        "\n",
        "비지도 학습은 번역 모델 개선에 다음과 같은 방식으로 기여할 수 있습니다:\n",
        "\n",
        "1. **데이터 분류**: 클러스터링을 통해 문서들을 주제별로 그룹화함으로써, 각 클러스터에 특화된 번역 모델을 학습시킬 수 있습니다. 이는 모델이 특정 주제의 문맥을 더 잘 이해하고 번역할 수 있도록 도와줍니다.\n",
        "2. **문맥 인식**: 클러스터링된 데이터를 활용해 번역 모델이 문맥에 따라 적절한 번역을 생성할 수 있도록 돕습니다. 주제별 특성을 반영한 학습은 자연스러운 번역을 가능하게 합니다.\n",
        "3. **오류 분석 및 개선**: 특정 클러스터에서 발생하는 번역 오류를 분석하고, 이를 기반으로 모델의 약점을 보완하는 데 활용할 수 있습니다.\n",
        "\n",
        "### 5. **결론 및 향후 작업**\n",
        "\n",
        "#### 5.1 결론\n",
        "\n",
        "- `seq2seq` 모델을 사용한 한문 고전 문서 번역의 정확도가 낮았으나, 데이터 전처리와 모델 설계 과정에서 유의미한 경험을 얻었습니다.\n",
        "- 비지도 학습 기법인 TF-IDF 벡터화와 클러스터링을 통해 문서의 주요 주제를 분석하고, 번역 모델 개선에 필요한 인사이트를 제공할 수 있었습니다.\n",
        "\n",
        "#### 5.2 향후 작업\n",
        "\n",
        "- **모델 개선**: `seq2seq` 모델의 성능을 개선하기 위해 다양한 기법을 시도하고, 데이터 증강과 하이퍼파라미터 최적화를 통해 모델을 재훈련할 필요가 있습니다.\n",
        "- **비지도 학습의 활용**: 클러스터링 결과를 활용하여 도메인 특화된 번역 모델을 개발하거나, 군집화된 데이터로 추가적인 학습을 진행할 수 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "vq45V_MVnH9j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExxZBjEdxn4g"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 경로 설정\n",
        "path = '/content/drive/MyDrive/hanja_korean_dataset/token'\n",
        "\n",
        "# 폴더 내 모든 parquet 파일 불러오기\n",
        "parquet_files = [file for file in os.listdir(path) if file.endswith('.parquet')]\n",
        "\n",
        "# 데이터프레임 리스트 초기화\n",
        "dfs = []\n",
        "\n",
        "# 각 parquet 파일을 데이터프레임으로 읽어서 리스트에 추가\n",
        "for file in parquet_files:\n",
        "    file_path = os.path.join(path, file)\n",
        "    df = pd.read_parquet(file_path)\n",
        "    dfs.append(df)\n",
        "\n",
        "# 모든 데이터프레임을 하나로 합치기\n",
        "merged_df = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "586CR6CJx63e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = merged_df\n",
        "print(df)"
      ],
      "metadata": {
        "id": "7PPLkds4x7f-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ff81a0-53b8-4083-da1c-8060ef6063e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                     hanja  \\\n",
            "0        [兵, 批, 參, 議, 崔, 尙, 儒, 進, 以, 韓, 啓, 宇, 爲, 盆, 山, ...   \n",
            "1        [吏, 曹, 啓, 目, 前, 五, 衛, 將, 朴, 枝, 藩, 名, 字, 改, 以, ...   \n",
            "2                           [上, 在, 景, 福, 宮, 停, 常, 參, 經, 筵]   \n",
            "3        [奎, 章, 閣, 啓, 曰, 檢, 書, 官, 李, 冕, 翼, 有, 身, 病, 勢, ...   \n",
            "4        [禮, 曹, 啓, 曰, 郊, 壇, 四, 孟, 朔, 遣, 禮, 郞, 看, 審, 有, ...   \n",
            "...                                                    ...   \n",
            "1022157  [義, 禁, 府, 啓, 曰, 戊, 子, 十, 一, 月, 二, 十, 二, 日, 前, ...   \n",
            "1022158                     [上, 在, 昌, 德, 宮, 停, 常, 參, 經, 筵]   \n",
            "1022159   [申, 時, 太, 白, 見, 於, 未, 地, 夜, 一, 更, 至, 四, 更, 月, 暈]   \n",
            "1022160  [大, 司, 憲, 金, 南, 重, 執, 義, 柳, 慶, 昌, 掌, 令, 申, 悅, ...   \n",
            "1022161  [政, 院, 啓, 曰, 勅, 使, 接, 見, 時, 酬, 酢, 說, 話, 依, 前, ...   \n",
            "\n",
            "                                                    korean  \n",
            "0        [병비, 에, 참의, 최상, 유, 는, 나왔다, 한계, 우, 를, 분산, 별장, 으...  \n",
            "1        [이조, 계목, 에전, 오, 위장, 박지, 번, 이, 이름, 을, 형진, 으로, 출...  \n",
            "2                 [상이, 경복궁, 에, 있었다, 상, 참과, 경연, 을, 정지, 하였다]  \n",
            "3        [규장각, 이, 아뢰, 기를, 검, 서관, 이면, 익, 이, 신병이, 있어서, 직임...  \n",
            "4        [예조, 가, 아뢰, 기를, 교단, 에, 사맹삭, 마다, 예조, 낭청, 을, 보내어...  \n",
            "...                                                    ...  \n",
            "1022157  [의금부, 가, 아뢰, 기를, 무자년, 1648, 인조, 26, 11월, 22일, ...  \n",
            "1022158           [상이, 창덕궁, 에, 있었다, 상, 참과, 경연, 을, 정지, 하였다]  \n",
            "1022159  [신시, 에, 태백성, 이, 미지, 에, 나타났다, 밤, 1, 경, 부터, 4, 경...  \n",
            "1022160  [대사헌, 김남중, 집의, 유경, 창, 장령, 신열, 도, ㆍ, 신속, 지평, 이수...  \n",
            "1022161  [비변사, 가, 아뢰, 기를, 정원, 이, 아뢰, 기를, 칙사, 를, 접견, 하실,...  \n",
            "\n",
            "[1022162 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한문과 한글 리스트를 공백으로 구분된 문자열로 변환\n",
        "df['hanja'] = df['hanja'].apply(lambda x: ' '.join(x))\n",
        "df['korean'] = df['korean'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# 변환된 결과 확인\n",
        "print(df['hanja'].head())\n",
        "print(df['korean'].head())"
      ],
      "metadata": {
        "id": "uVue7BNUyD53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "305543a1-fe44-4277-b247-77c15a1a05d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                    兵 批 參 議 崔 尙 儒 進 以 韓 啓 宇 爲 盆 山 別 將\n",
            "1    吏 曹 啓 目 前 五 衛 將 朴 枝 藩 名 字 改 以 瀅 鎭 出 身 姜 斗 鍵 名 ...\n",
            "2                                  上 在 景 福 宮 停 常 參 經 筵\n",
            "3    奎 章 閣 啓 曰 檢 書 官 李 冕 翼 有 身 病 勢 難 供 職 減 下 其 代 以 ...\n",
            "4    禮 曹 啓 曰 郊 壇 四 孟 朔 遣 禮 郞 看 審 有 無 頉 自 該 曹 草 記 事 ...\n",
            "Name: hanja, dtype: object\n",
            "0               병비 에 참의 최상 유 는 나왔다 한계 우 를 분산 별장 으로 삼았다\n",
            "1    이조 계목 에전 오 위장 박지 번 이 이름 을 형진 으로 출신 강 두건 이 이름 을...\n",
            "2                        상이 경복궁 에 있었다 상 참과 경연 을 정지 하였다\n",
            "3    규장각 이 아뢰 기를 검 서관 이면 익 이 신병이 있어서 직임 을 수행 하기 어려운...\n",
            "4    예조 가 아뢰 기를 교단 에 사맹삭 마다 예조 낭청 을 보내어 탈 이 있는지를 간 ...\n",
            "Name: korean, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "eZTysulFycCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(df, lang1_col, lang2_col, reverse=False):\n",
        "    print(\"Reading lines from DataFrame...\")\n",
        "\n",
        "    # DataFrame에서 문장 쌍 추출\n",
        "    pairs = list(zip(df[lang1_col], df[lang2_col]))\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2_col)\n",
        "        output_lang = Lang(lang1_col)\n",
        "    else:\n",
        "        input_lang = Lang(lang1_col)\n",
        "        output_lang = Lang(lang2_col)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "pNc6lPHl9QFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 5\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "pggvJL1uTWCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 준비 함수\n",
        "def prepareData(df, lang1_col, lang2_col, reverse=False):\n",
        "    # readLangs 함수를 호출하여 언어 및 쌍 데이터 추출\n",
        "    input_lang, output_lang, pairs = readLangs(df, lang1_col, lang2_col, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "\n",
        "    # 쌍 데이터에서 단어 세기\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "# 데이터 준비\n",
        "input_lang, output_lang, pairs = prepareData(df, 'korean', 'hanja', True)\n",
        "\n",
        "# 무작위로 쌍 데이터 출력\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "id": "337eCKsDzVsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3fad139-4e59-4edf-9c79-0af52e1af61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines from DataFrame...\n",
            "Read 1022162 sentence pairs\n",
            "Trimmed to 20091 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "hanja 418\n",
            "korean 541\n",
            "['聽 輪 對', '윤대 를 들었다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "CJIPKtFG1Ryh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "pYSxA3b514xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "u4rBQtBj5OXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def pad_sequence(seq, max_length, padding_value=0):\n",
        "    return seq + [padding_value] * (max_length - len(seq)) if len(seq) < max_length else seq[:max_length]\n",
        "\n",
        "def get_dataloader(df, batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData(df, 'korean', 'hanja', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids = pad_sequence(inp_ids, MAX_LENGTH, EOS_token)\n",
        "        tgt_ids = pad_sequence(tgt_ids, MAX_LENGTH, EOS_token)\n",
        "        input_ids[idx, :] = inp_ids\n",
        "        target_ids[idx, :] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader"
      ],
      "metadata": {
        "id": "nsHV5x9v17p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "mL9XorYL2edp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "ORV1JVK32sLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "S4Itn_dT2u-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "nhF4EYtaNrhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn"
      ],
      "metadata": {
        "id": "3c6zYdgt2ylE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터프레임에서 훈련 및 테스트 세트를 생성합니다.\n",
        "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "HHs1uiwDTA7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "c43gmdnn4q9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "# 훈련 및 테스트 데이터 로더를 가져옵니다.\n",
        "train_input_lang, train_output_lang, train_dataloader = get_dataloader(train_df, batch_size) # train_df 사용\n",
        "test_input_lang, test_output_lang, test_dataloader = get_dataloader(test_df, batch_size) # test_df 사용\n",
        "\n",
        "encoder = EncoderRNN(train_input_lang.n_words, hidden_size).to(device) # train_input_lang 사용\n",
        "decoder = AttnDecoderRNN(hidden_size, train_output_lang.n_words).to(device) # train_output_lang 사용\n",
        "\n",
        "# 훈련 데이터 로더를 사용하여 모델 훈련\n",
        "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995
        },
        "id": "LSO0YL2F5hkg",
        "outputId": "b057b7d5-8148-4964-9839-76c263a77c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines from DataFrame...\n",
            "Read 919945 sentence pairs\n",
            "Trimmed to 18133 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "hanja 402\n",
            "korean 517\n",
            "Reading lines from DataFrame...\n",
            "Read 102217 sentence pairs\n",
            "Trimmed to 1958 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "hanja 177\n",
            "korean 181\n",
            "1m 54s (- 28m 37s) (5 6%) 0.2122\n",
            "3m 43s (- 26m 1s) (10 12%) 0.0725\n",
            "5m 41s (- 24m 38s) (15 18%) 0.0634\n",
            "7m 31s (- 22m 34s) (20 25%) 0.0589\n",
            "9m 17s (- 20m 25s) (25 31%) 0.0564\n",
            "11m 10s (- 18m 37s) (30 37%) 0.0550\n",
            "12m 57s (- 16m 39s) (35 43%) 0.0541\n",
            "14m 41s (- 14m 41s) (40 50%) 0.0535\n",
            "16m 23s (- 12m 44s) (45 56%) 0.0530\n",
            "18m 5s (- 10m 51s) (50 62%) 0.0528\n",
            "19m 50s (- 9m 1s) (55 68%) 0.0525\n",
            "21m 34s (- 7m 11s) (60 75%) 0.0525\n",
            "23m 17s (- 5m 22s) (65 81%) 0.0522\n",
            "25m 0s (- 3m 34s) (70 87%) 0.0521\n",
            "26m 43s (- 1m 46s) (75 93%) 0.0522\n",
            "28m 26s (- 0m 0s) (80 100%) 0.0520\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ],
      "metadata": {
        "id": "4pVt42Ry5lac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64bb5267-f687-4a16-9e18-4ab4f8ae7ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> 召 對\n",
            "= 소대 하였다\n",
            "< 행주 017 하였다 인정전 <EOS>\n",
            "\n",
            "> 御 夕 講\n",
            "= 석 강 에 나아갔다\n",
            "< 주강 에 나아갔다 우박 <EOS>\n",
            "\n",
            "> 庚 寅 氷\n",
            "= 얼음 이 얼었다\n",
            "< 가 큰 청나라 <EOS>\n",
            "\n",
            "> 壬 寅 視 事\n",
            "= 정사 를 보았다\n",
            "< 머물렀다 나아갔다 삼전 <EOS>\n",
            "\n",
            "> 己 巳 召 對\n",
            "= 소대 하였다\n",
            "< 321 잠시 광주 <EOS>\n",
            "\n",
            "> 有 政\n",
            "= 정사 가 있었다\n",
            "< 불었다 돌아갔다 <EOS>\n",
            "\n",
            "> 別 講\n",
            "= 별 강하였다\n",
            "< 청 나아갔다 우박 <EOS>\n",
            "\n",
            "> 夕 講\n",
            "= 석 강하였다\n",
            "< 행주 하였다 박천군 <EOS>\n",
            "\n",
            "> 御 夕 講\n",
            "= 석 강 에 나아갔다\n",
            "< 주강 에 나아갔다 우박 <EOS>\n",
            "\n",
            "> 召 對\n",
            "= 소대 를 행 하였다\n",
            "< 행주 017 하였다 인정전 <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "id": "14W7gzvY7aXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab98e6db-419f-4210-c895-1ce4fc1a15b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20200506-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.font_manager as fm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "plt.rcParams['axes.unicode_minus'] =False"
      ],
      "metadata": {
        "id": "N8-wHjCKEi_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(test_df.iloc[6,0])"
      ],
      "metadata": {
        "id": "PcIehg-bEXwA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "a6951e56-a91b-4c0d-c60d-bf32e2de2f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = 丙 子 日 有 重 暈\n",
            "output = 불었다 큰 월식 돌아갔다 <EOS>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-90c5e6256444>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
            "<ipython-input-47-90c5e6256444>:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + output_words)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "비지도학습"
      ],
      "metadata": {
        "id": "nCCtDRiaHvq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 경로 설정\n",
        "path = '/content/drive/MyDrive/hanja_korean_dataset/token'\n",
        "\n",
        "# 폴더 내 모든 parquet 파일 불러오기\n",
        "parquet_files = [file for file in os.listdir(path) if file.endswith('.parquet')]\n",
        "\n",
        "# 데이터프레임 리스트 초기화\n",
        "dfs = []\n",
        "\n",
        "# 각 parquet 파일을 데이터프레임으로 읽어서 리스트에 추가\n",
        "for file in parquet_files:\n",
        "    file_path = os.path.join(path, file)\n",
        "    df = pd.read_parquet(file_path)\n",
        "    dfs.append(df)\n",
        "\n",
        "# 모든 데이터프레임을 하나로 합치기\n",
        "merged_df = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "2VWFz7hjH3iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = merged_df\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4-iLAYFH8HA",
        "outputId": "76c36b29-f9de-4a23-a45c-a33facf3ee8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                     hanja  \\\n",
            "0        [兵, 批, 參, 議, 崔, 尙, 儒, 進, 以, 韓, 啓, 宇, 爲, 盆, 山, ...   \n",
            "1        [吏, 曹, 啓, 目, 前, 五, 衛, 將, 朴, 枝, 藩, 名, 字, 改, 以, ...   \n",
            "2                           [上, 在, 景, 福, 宮, 停, 常, 參, 經, 筵]   \n",
            "3        [奎, 章, 閣, 啓, 曰, 檢, 書, 官, 李, 冕, 翼, 有, 身, 病, 勢, ...   \n",
            "4        [禮, 曹, 啓, 曰, 郊, 壇, 四, 孟, 朔, 遣, 禮, 郞, 看, 審, 有, ...   \n",
            "...                                                    ...   \n",
            "1022157  [義, 禁, 府, 啓, 曰, 戊, 子, 十, 一, 月, 二, 十, 二, 日, 前, ...   \n",
            "1022158                     [上, 在, 昌, 德, 宮, 停, 常, 參, 經, 筵]   \n",
            "1022159   [申, 時, 太, 白, 見, 於, 未, 地, 夜, 一, 更, 至, 四, 更, 月, 暈]   \n",
            "1022160  [大, 司, 憲, 金, 南, 重, 執, 義, 柳, 慶, 昌, 掌, 令, 申, 悅, ...   \n",
            "1022161  [政, 院, 啓, 曰, 勅, 使, 接, 見, 時, 酬, 酢, 說, 話, 依, 前, ...   \n",
            "\n",
            "                                                    korean  \n",
            "0        [병비, 에, 참의, 최상, 유, 는, 나왔다, 한계, 우, 를, 분산, 별장, 으...  \n",
            "1        [이조, 계목, 에전, 오, 위장, 박지, 번, 이, 이름, 을, 형진, 으로, 출...  \n",
            "2                 [상이, 경복궁, 에, 있었다, 상, 참과, 경연, 을, 정지, 하였다]  \n",
            "3        [규장각, 이, 아뢰, 기를, 검, 서관, 이면, 익, 이, 신병이, 있어서, 직임...  \n",
            "4        [예조, 가, 아뢰, 기를, 교단, 에, 사맹삭, 마다, 예조, 낭청, 을, 보내어...  \n",
            "...                                                    ...  \n",
            "1022157  [의금부, 가, 아뢰, 기를, 무자년, 1648, 인조, 26, 11월, 22일, ...  \n",
            "1022158           [상이, 창덕궁, 에, 있었다, 상, 참과, 경연, 을, 정지, 하였다]  \n",
            "1022159  [신시, 에, 태백성, 이, 미지, 에, 나타났다, 밤, 1, 경, 부터, 4, 경...  \n",
            "1022160  [대사헌, 김남중, 집의, 유경, 창, 장령, 신열, 도, ㆍ, 신속, 지평, 이수...  \n",
            "1022161  [비변사, 가, 아뢰, 기를, 정원, 이, 아뢰, 기를, 칙사, 를, 접견, 하실,...  \n",
            "\n",
            "[1022162 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"토큰화된 데이터를 문자열로 변환 중...\")\n",
        "# 리스트 형태의 토큰을 공백으로 연결하여 하나의 문자열로 변환\n",
        "df['processed_text'] = df['korean'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# TF-IDF 벡터라이저 초기화\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=1, max_df=0.95, stop_words=None)\n",
        "\n",
        "# TF-IDF 행렬 생성\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['processed_text'])\n",
        "\n",
        "print(f\"TF-IDF 행렬의 크기: {tfidf_matrix.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z73yU8gesAEy",
        "outputId": "61c1cad0-e6bf-43a4-a3da-00453adc06fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토큰화된 데이터를 문자열로 변환 중...\n",
            "TF-IDF 행렬의 크기: (1022162, 346378)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# 샘플링할 문서 수\n",
        "sample_size = 10000\n",
        "\n",
        "# TF-IDF 행렬에서 샘플 추출\n",
        "sample_indices = np.random.choice(tfidf_matrix.shape[0], sample_size, replace=False)\n",
        "sample_matrix = tfidf_matrix[sample_indices]"
      ],
      "metadata": {
        "id": "d-LV8SUFhGre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 문서 간 유사도 계산\n",
        "sample_similarity_matrix = cosine_similarity(sample_matrix)\n",
        "\n",
        "# 상위 5개 문서 간의 유사도 (예: 첫 5문서 간 유사도)\n",
        "print(sample_similarity_matrix[:5, :5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLJlGlBwdx2M",
        "outputId": "84463fb9-3c08-43a9-a1a0-f31ec0d5ccd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.04872314 0.04497555 0.01289764 0.00922311]\n",
            " [0.04872314 1.         0.11641303 0.0448963  0.00913705]\n",
            " [0.04497555 0.11641303 1.         0.01179451 0.00843426]\n",
            " [0.01289764 0.0448963  0.01179451 1.         0.00747182]\n",
            " [0.00922311 0.00913705 0.00843426 0.00747182 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-means 클러스터링\n",
        "num_clusters = 5  # 군집의 수를 설정합니다.\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(sample_matrix)\n",
        "\n",
        "# 각 문서의 군집 레이블\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# 군집 중심 (각 군집의 중심 벡터)\n",
        "cluster_centers = kmeans.cluster_centers_\n",
        "\n",
        "print(\"Cluster labels for the first 10 documents:\", cluster_labels[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2LMDRrMheKj",
        "outputId": "d5e0244d-77d8-46a1-e654-6fb27fb306bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster labels for the first 10 documents: [3 3 3 1 2 4 3 4 4 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 주요 단어 추출 함수 정의\n",
        "def get_top_words_for_cluster(tfidf_matrix, cluster_labels, kmeans_model, feature_names, num_words=10):\n",
        "    top_words = []\n",
        "    for i in range(len(set(cluster_labels))):\n",
        "        cluster_center = kmeans_model.cluster_centers_[i]\n",
        "        top_indices = cluster_center.argsort()[-num_words:][::-1]\n",
        "        top_words.append([feature_names[j] for j in top_indices])\n",
        "    return top_words\n",
        "\n",
        "# TF-IDF 벡터라이저에서 feature_names 추출\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# 주요 단어 추출\n",
        "top_words_per_cluster = get_top_words_for_cluster(sample_matrix, cluster_labels, kmeans, feature_names)\n",
        "print(\"Top words per cluster:\", top_words_per_cluster)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IiT_3kshhB1",
        "outputId": "10fc55c9-f520-4221-b198-0bd3c7f2ac15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top words per cluster: [['전망', '단자', '들이니', '들이라', '낙점', '하였다', '할지', '전교', '승지', '차하'], ['소대', '전지', '나오지', '추고만', '파직', '관련', '패초', '대한', '않은', '하였다'], ['있었다', '참과', '상이', '정지', '경연', '창덕궁', '창경궁', '하였다', '경복궁', '경덕궁'], ['하니', '전교', '아뢰', '기를', '알았다고', '하였다', '한다고', '패초', '어떻겠습니까', '윤허'], ['으로', '하였다', '하여', '하기를', '하고', '에서', '하는', '에게', '하지', '전교']]\n"
          ]
        }
      ]
    }
  ]
}